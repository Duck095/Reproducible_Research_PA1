---
title: "R Notebook"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

LAB_5_6_TranDucNgocLong_SE173342

## Má»¥c tiÃªu há»c táº­p

Sau khi hoÃ n thÃ nh bÃ i lab nÃ y, cÃ¡c báº¡n sáº½ cÃ³ thá»ƒ:

1.  Hiá»ƒu cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n vá» mÃ´ hÃ¬nh tuyáº¿n tÃ­nh
2.  Sá»­ dá»¥ng cÃ¡c hÃ m `lm()` vÃ  `loess()` Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh
3.  Trá»±c quan hÃ³a mÃ´ hÃ¬nh vÃ  dá»± Ä‘oÃ¡n
4.  PhÃ¢n tÃ­ch residual Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh
5.  Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ báº¥t thÆ°á»ng trong dá»¯ liá»‡u
6.  Sá»­ dá»¥ng cÃ¡c hÃ m há»— trá»£ nhÆ° `add_predictions()` vÃ  `add_residuals()`

```{r}
# install.packages(c("tidyverse", "modelr"))

library("tidyverse")
library("modelr")

```

```{r}
# Thiáº¿t láº­p xá»­ lÃ½ giÃ¡ trá»‹ missing
options(na.action = na.warn)
```

## Pháº§n 1: MÃ´ hÃ¬nh Ä‘Æ¡n giáº£n vÃ  áº£nh hÆ°á»Ÿng cá»§a outliers (25 Ä‘iá»ƒm)

### 1.1. Táº¡o dá»¯ liá»‡u mÃ´ phá»ng vá»›i Student's t-distribution

```{r}
# Táº¡o dá»¯ liá»‡u vá»›i t-distribution
sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)

print(sim1a)

```

The **t-distribution** (cÃ²n gá»i lÃ  **Studentâ€™s t-distribution**) thÆ°á»ng
Ä‘Æ°á»£c dÃ¹ng trong thá»‘ng kÃª, Ä‘áº·c biá»‡t khi:

-   Cá»¡ máº«u nhá» (**n \< 30**).

-   PhÆ°Æ¡ng sai dÃ¢n sá»‘ (ÏƒÂ²) chÆ°a biáº¿t.

-   Ta thay tháº¿ Ä‘á»™ lá»‡ch chuáº©n tháº­t báº±ng **Æ°á»›c lÆ°á»£ng tá»« máº«u**.

-   Náº¿u Zâˆ¼N(0,1) (chuáº©n hÃ³a) vÃ  Vâˆ¼Ï‡2(Î½) (phÃ¢n phá»‘i Chi-square vá»›i Î½ báº­c
    tá»± do), Ä‘á»™c láº­p nhau, thÃ¬:

```         
T=Z/sqrt(Î½T)
```

-   sáº½ tuÃ¢n theo **t-distribution** vá»›i Î½ báº­c tá»± do (degrees of freedom,
    df).

```{r}
# Váº½ biá»ƒu Ä‘á»“ cÃ³ Ä‘Æ°á»ng há»“i quy
ggplot(sim1a, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "MÃ´ hÃ¬nh tuyáº¿n tÃ­nh vá»›i t-distribution",
       x = "X", y = "Y")
```

### 1.2. Sá»­ dá»¥ng PhÆ°Æ¡ng phÃ¡p trá»±c quan Ä‘á»ƒ So sÃ¡nh

```{r}
# HÃ m táº¡o dá»¯ liá»‡u vá»›i t-distribution
simt <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rt(length(x), df = 2),
    .id = i
  )
}

# Táº¡o 12 bá»™ dá»¯ liá»‡u mÃ´ phá»ng
sims <-  map_dfr(1:12, simt)

```

```{r}
# Váº½ biá»ƒu Ä‘á»“ vá»›i 12 panel
ggplot(sims, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "red", se = FALSE) +
  facet_wrap(~.id, ncol = 4) +
  labs(title = "12 mÃ´ phá»ng vá»›i t-distribution")
```

### 1.3. So sÃ¡nh vá»›i normal distribution

```{r}
# HÃ m táº¡o dá»¯ liá»‡u vá»›i normal distribution
sim_norm <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rnorm(length(x)),
    .id = i
  )
}

# Táº¡o 12 bá»™ dá»¯ liá»‡u vá»›i normal distribution
simdf_norm <-  map_dfr(1:12, sim_norm)

```

```{r}
# Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh
ggplot(simdf_norm, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "red", se = FALSE) +
  facet_wrap(~.id, ncol = 4) +
  labs(title = "12 mÃ´ phá»ng vá»›i Normal distribution")
```

### 1.4. So sÃ¡nh phÃ¢n phá»‘i

#### Má»¥c tiÃªu

-   Trá»±c quan hÃ³a sá»± khÃ¡c biá»‡t giá»¯a Normal distribution vÃ  Student-t
    distribution.

-   Chá»©ng minh: Student-t cÃ³ tail dÃ y hÆ¡n, tá»©c lÃ  xÃ¡c suáº¥t gáº·p outlier
    cao hÆ¡n.

\*\* Thá»±c hiá»‡n váº½ Normal distribution vÃ  t-distributionÄ‘á»ƒ Ä‘Ã¡nh giÃ¡:\*\*

-   ÄÆ°á»ng Normal distribution (chuáº©n) cÃ³ dáº¡ng â€œchuÃ´ngâ€, táº­p trung nhiá»u
    á»Ÿ trung tÃ¢m (x = 0) vÃ  tail má»ng.

-   ÄÆ°á»ng t-distribution vá»›i df = 2 cÃ³ dáº¡ng tÆ°Æ¡ng tá»± nhÆ°ng Ä‘uÃ´i dÃ y hÆ¡n
    (heavy tails) â†’ xÃ¡c suáº¥t quan sÃ¡t Ä‘Æ°á»£c giÃ¡ trá»‹ xa trung tÃ¢m cao hÆ¡n.

-   Khi df (degrees of freedom) tÄƒng, phÃ¢n phá»‘i t dáº§n dáº§n tiá»‡m cáº­n
    Normal distribution.

```{r}
# Váº½ so sÃ¡nh density cá»§a t-distribution vÃ  normal distribution
tibble(
  x = seq(-5, 5, length.out = 100),
  normal = dnorm(x),
  student_t = dt(x, df = 2)
) %>%
  pivot_longer(-x, names_to="distribution", values_to="density") %>%
  ggplot(aes(x = x, y = density, colour = distribution)) +
  geom_line(size = 1.2) +
  labs(title = "So sÃ¡nh Normal distribution vÃ  t-distribution",
       x = "GiÃ¡ trá»‹", y = "Máº­t Ä‘á»™ xÃ¡c suáº¥t")

# TÃ­nh xÃ¡c suáº¥t tail
# XÃ¡c suáº¥t > 2 vá»›i Normal distribution:

cat("xÃ¡c suáº¥t > 2 vá»›i Normal distribution:", pnorm(2, lower.tail = FALSE), "\n")
# XÃ¡c suáº¥t > 2 vá»›i t-distribution (df=2):
cat("xÃ¡c suáº¥t > 2 vá»›i t-distribution (df=2):", pt(2, df = 2, lower.tail = FALSE), "\n")

```

#### Sá»¬ dá»¥ng t-distribution khi:

-   Dá»¯ liá»‡u Ã­t (small sample size).

-   Cáº§n mÃ´ hÃ¬nh robust hÆ¡n vá»›i outlier.

-   Trong Bayesian inference, noise thÆ°á»ng Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a báº±ng
    Student-t thay vÃ¬ Gaussian.

##### Má»¥c tiÃªu so sÃ¡nh:

-   Æ¯á»›c lÆ°á»£ng tham sá»‘: vá»›i dá»¯ liá»‡u Ã­t (sample nhá»), ta hay dÃ¹ng
    t-distribution Ä‘á»ƒ pháº£n Ã¡nh Ä‘á»™ báº¥t Ä‘á»‹nh cao hÆ¡n so vá»›i Normal.

-   PhÃ¡t hiá»‡n outlier: t-distribution vá»›i heavy tails cÃ³ thá»ƒ chá»‘ng láº¡i
    áº£nh hÆ°á»Ÿng cá»§a outlier tá»‘t hÆ¡n trong má»™t sá»‘ mÃ´ hÃ¬nh (vÃ­ dá»¥ Bayesian
    inference).

-   Regularization: Ã½ tÆ°á»Ÿng â€œÄ‘uÃ´i dÃ yâ€ gáº§n giá»‘ng L1 penalty (cho phÃ©p
    giÃ¡ trá»‹ lá»›n hiáº¿m khi xáº£y ra) so vá»›i Gaussian prior (L2 penalty).

**CÃ¢u 1: (8 Ä‘iá»ƒm)** Táº¡i sao t-distribution vá»›i df=2 táº¡o ra nhiá»u giÃ¡ trá»‹
cá»±c trá»‹ (outliers) hÆ¡n so vá»›i normal distribution? HÃ£y giáº£i thÃ­ch vÃ  so
sÃ¡nh xÃ¡c suáº¥t P(X \> 2) cá»§a hai phÃ¢n phá»‘i nÃ y.

**ÄÃ¡p Ã¡n:**

```         
T-distribution vá»›i df=2 cÃ³ Ä‘uÃ´i dÃ y hÆ¡n normal distribution, nÃªn nÃ³ cho nhiá»u giÃ¡ trá»‹ cá»±c trá»‹ (outliers) hÆ¡n.
VÃ­ dá»¥, ğ‘ƒ(ğ‘‹>2) vá»›i t(df=2) lá»›n hÆ¡n nhiá»u so vá»›i normal(0,1) (khoáº£ng 0.1 so vá»›i 0.023).
```

**CÃ¢u 2: (8 Ä‘iá»ƒm)** Quan sÃ¡t 12 biá»ƒu Ä‘á»“ mÃ´ phá»ng vá»›i t-distribution vÃ 
normal distribution. MÃ´ hÃ¬nh nÃ o cÃ³ Ä‘Æ°á»ng há»“i quy á»•n Ä‘á»‹nh hÆ¡n vÃ  táº¡i
sao?

**ÄÃ¡p Ã¡n:**

```         
MÃ´ hÃ¬nh vá»›i normal distribution cÃ³ Ä‘Æ°á»ng há»“i quy á»•n Ä‘á»‹nh hÆ¡n vÃ¬ Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers.
MÃ´ hÃ¬nh vá»›i t-distribution dao Ä‘á»™ng nhiá»u hÆ¡n do cÃ¡c outliers lÃ m áº£nh hÆ°á»Ÿng máº¡nh Ä‘áº¿n káº¿t quáº£.
```

**CÃ¢u 3: (9 Ä‘iá»ƒm)** Náº¿u báº¡n cÃ³ má»™t dataset thá»±c táº¿ vá»›i nhiá»u outliers,
báº¡n sáº½ chá»n phÆ°Æ¡ng phÃ¡p nÃ o Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh? Äá» xuáº¥t Ã­t nháº¥t 2 giáº£i
phÃ¡p.

**ÄÃ¡p Ã¡n:**

```         
Náº¿u dataset cÃ³ nhiá»u outliers, ta cÃ³ thá»ƒ:

DÃ¹ng há»“i quy robust (nhÆ° M-estimator) Ä‘á»ƒ giáº£m áº£nh hÆ°á»Ÿng cá»§a outliers.

Loáº¡i hoáº·c Ä‘iá»u chá»‰nh outliers trÆ°á»›c khi xÃ¢y dá»±ng mÃ´ hÃ¬nh.
```

## Pháº§n 2: CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘o khoáº£ng cÃ¡ch khÃ¡c nhau (20 Ä‘iá»ƒm)

TÃ¬m hiá»ƒu khÃ¡i niá»‡m tÃ­nh toÃ¡n Ä‘á»ƒ fit má»™t Ä‘Æ°á»ng há»“i quy tuyáº¿n tÃ­nh Ä‘Æ¡n
giáº£n:

$$ \hat{y} = Î²0â€‹+Î²1â€‹x $$ thay vÃ¬ dÃ¹ng cÃ´ng thá»©c `lm(y ~ x)` (OLS â€“
ordinary least squares), cÃ¡c báº¡n tÃ¬m hiá»ƒu **hÃ m Ä‘o sai sá»‘ (loss
function)** rá»“i dÃ¹ng `optim()` Ä‘á»ƒ tÃ¬m tham sá»‘ tá»‘i Æ°u.

-   2 loáº¡i loss function:

------------------------------------------------------------------------

### 1. MAD (Mean Absolute Distance)

$$
L(\beta_0, \beta_1) = \frac{1}{n} \sum |y_i - \hat{y}_i|
$$

------------------------------------------------------------------------

### 2. RMSD (Root Mean Squared Distance)

$$
L(\beta_0, \beta_1) = \frac{1}{n} \sum (y_i - \hat{y}_i)^2
$$

### 2.1. Mean Absolute Deviation

```{r}
# HÃ m Ä‘o khoáº£ng cÃ¡ch báº±ng Mean Absolute Distance
measure_distance <- function(mod, data) {
  diff <- data$y - make_prediction(mod, data)
  mean(abs(diff))
}

# HÃ m dá»± Ä‘oÃ¡n
make_prediction <- function(mod, data) {
mod [1] + mod [2] * data$x
}

```

-   mod lÃ  vector tham sá»‘ [Î²0, Î²1].

-   data\$x lÃ  dá»¯ liá»‡u Ä‘áº§u vÃ o. - \>Tráº£ vá» giÃ¡ trá»‹ dá»± Ä‘oÃ¡n $$ \hat{y}$$

```{r}
# TÃ¬m tham sá»‘ tá»‘i Æ°u vá»›i MAD
best_mad <- optim(c(0, 0), measure_distance, data = sim1a)
cat("Tham sá»‘ tá»‘i Æ°u vá»›i MAD:", best_mad$par, "\n")

# HÃ m Ä‘o khoáº£ng cÃ¡ch báº±ng Root Mean Squared Distance( TÃ­nh sai sá»‘ tuyá»‡t Ä‘á»‘i giá»¯a giÃ¡ trá»‹ tháº­t y vÃ  dá»± Ä‘oÃ¡n Å·.)

# DÃ¹ng trung bÃ¬nh Ä‘á»ƒ cÃ³ giÃ¡ trá»‹ tá»•ng quÃ¡t.
measure_distance_ls <- function(mod, data) {
  diff <- data$y - make_prediction(mod, data)
  sqrt(mean(diff^2))
}
```

-   optim(c(0, 0), ...) khá»Ÿi táº¡o Î²0 = 0, Î²1 = 0.
-   TÃ¬m cáº·p [Î²0, Î²1] sao cho hÃ m MAD nhá» nháº¥t.

```{r}
# TÃ¬m tham sá»‘ tá»‘i Æ°u vá»›i RMSD
best_rmsd <- optim(c(0, 0), measure_distance_ls, data = sim1a)
cat("Tham sá»‘ tá»‘i Æ°u vá»›i RMSD:", best_rmsd$par, "\n")
```

-   Giá»‘ng MSE (Mean Squared Error), chá»‰ khÃ¡c lÃ  láº¥y cÄƒn báº­c 2.

-   Pháº¡t náº·ng cÃ¡c sai sá»‘ lá»›n â†’ nháº¡y cáº£m vá»›i outliers.

### CÃ¢u há»i vÃ  Ä‘Ã¡p Ã¡n - Pháº§n 2 (20 Ä‘iá»ƒm)

**CÃ¢u 1: (7 Ä‘iá»ƒm)** Giáº£i thÃ­ch sá»± khÃ¡c biá»‡t giá»¯a Mean Absolute Distance
(MAD) vÃ  Root Mean Squared Distance (RMSD). Khi nÃ o nÃªn sá»­ dá»¥ng MAD?

**ÄÃ¡p Ã¡n:**

MAD (Mean Absolute Distance) lÃ  trung bÃ¬nh giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cá»§a sai sá»‘,
cÃ²n RMSD (Root Mean Squared Distance) lÃ  cÄƒn báº­c hai cá»§a trung bÃ¬nh bÃ¬nh
phÆ°Æ¡ng sai sá»‘.

MAD Ã­t nháº¡y cáº£m vá»›i outliers vÃ¬ chá»‰ tÃ­nh trá»‹ tuyá»‡t Ä‘á»‘i, khÃ´ng bÃ¬nh
phÆ°Æ¡ng sai sá»‘.

NÃªn dÃ¹ng MAD khi dá»¯ liá»‡u cÃ³ outliers hoáº·c muá»‘n giáº£m áº£nh hÆ°á»Ÿng cá»§a cÃ¡c
sai sá»‘ cá»±c lá»›n.

**CÃ¢u 2: (6 Ä‘iá»ƒm)** Trong code trÃªn, táº¡i sao hÃ m `optim()` cÃ³ thá»ƒ cho
káº¿t quáº£ khÃ¡c nhau tÃ¹y thuá»™c vÃ o giÃ¡ trá»‹ khá»Ÿi táº¡o?

**ÄÃ¡p Ã¡n:**

HÃ m optim() sá»­ dá»¥ng thuáº­t toÃ¡n tá»‘i Æ°u dá»±a trÃªn Ä‘iá»ƒm khá»Ÿi táº¡o.

GiÃ¡ trá»‹ khá»Ÿi táº¡o khÃ¡c nhau cÃ³ thá»ƒ dáº«n Ä‘áº¿n tÃ¬m Ä‘Æ°á»£c cá»±c trá»‹ cá»¥c bá»™ khÃ¡c
nhau, nÃªn káº¿t quáº£ cÅ©ng khÃ¡c nhau.

**CÃ¢u 3: (7 Ä‘iá»ƒm)** Viáº¿t cÃ´ng thá»©c toÃ¡n há»c cho cáº£ MAD vÃ  RMSD. Giáº£i
thÃ­ch táº¡i sao RMSD "pháº¡t" outliers náº·ng hÆ¡n MAD.

**ÄÃ¡p Ã¡n:**

-   CÃ´ng thá»©c: $$
    \text{MAD} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
    $$ $$
    \text{RMSD} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}
    $$

-   RMSD "pháº¡t" outliers náº·ng hÆ¡n vÃ¬ sai sá»‘ Ä‘Æ°á»£c bÃ¬nh phÆ°Æ¡ng, lÃ m cho
    cÃ¡c lá»—i lá»›n cÃ³ áº£nh hÆ°á»Ÿng lá»›n hÆ¡n trong tÃ­nh toÃ¡n.

## Pháº§n 3: Trá»±c quan hÃ³a mÃ´ hÃ¬nh (25 Ä‘iá»ƒm)

### 3.1. So sÃ¡nh lm() vÃ  loess()

```{r}
# Sá»­ dá»¥ng dá»¯ liá»‡u sim1 cÃ³ sáºµn trong modelr
# XÃ¢y dá»±ng mÃ´ hÃ¬nh
sim1_loess <- loess(y ~  x, data = sim1)
sim1_lm <- lm(y ~  x, data= sim1)
```

```{r}
# ThÃªm predictions vÃ  residuals
sim1_extended <- sim1 %>%
  add_residuals(sim1_lm, var = "resid_lm") %>%
  add_predictions(sim1_lm, var = "pred_lm") %>%
  add_residuals(sim1_loess, var = "resid_loess") %>%
  add_predictions(sim1_loess, var = "pred_loess")

```

```{r}
# Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh
ggplot(sim1_extended, aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred_lm), color = "red", size = 1) +
  geom_line(aes(y = pred_loess), color = "blue", size = 1) +
  labs(title = "So sÃ¡nh Linear Model (Ä‘á») vÃ  LOESS (xanh)",
       x = "X", y = "Y")
```

### `lm()` â€“ **Linear Model**

-   DÃ¹ng Ä‘á»ƒ xÃ¢y dá»±ng **mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh** (linear regression).

-   Giáº£ Ä‘á»‹nh má»‘i quan há»‡ giá»¯a biáº¿n Ä‘á»™c láº­p x vÃ  biáº¿n phá»¥ thuá»™c y lÃ 
    **tuyáº¿n tÃ­nh** hoáº·c cÃ³ thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c báº±ng cÃ¡c biáº¿n biáº¿n Ä‘á»•i
    (nhÆ° Ä‘a thá»©c).

### `loess()` â€“ **Local Regression (phi tuyáº¿n)**

-   LÃ  **mÃ´ hÃ¬nh há»“i quy cá»¥c bá»™** (local regression, local polynomial
    regression).

-   KhÃ´ng giáº£ Ä‘á»‹nh má»‘i quan há»‡ tuyáº¿n tÃ­nh toÃ n cá»¥c, mÃ  tÃ¬m **Ä‘Æ°á»ng cong
    trÆ¡n** mÃ´ táº£ dá»¯ liá»‡u tá»‘t hÆ¡n khi quan há»‡ giá»¯a x vÃ  y lÃ  phi tuyáº¿n.

## **Studentâ€™s t-distribution**

The **t-distribution** (cÃ²n gá»i lÃ  **Studentâ€™s t-distribution**)

NÃ³ thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng trong thá»‘ng kÃª khi:

-   Cá»¡ máº«u nhá» (**n \< 30**).

-   PhÆ°Æ¡ng sai dÃ¢n sá»‘ (ÏƒÂ²) chÆ°a biáº¿t.

-   Thay tháº¿ Ä‘á»™ lá»‡ch chuáº©n tháº­t báº±ng **Æ°á»›c lÆ°á»£ng tá»« máº«u**.

Náº¿u Zâˆ¼N(0,1) (chuáº©n hÃ³a) vÃ  Vâˆ¼Ï‡2 (phÃ¢n phá»‘i Chi-square vá»›i Î½ báº­c tá»± do),
Ä‘á»™c láº­p nhau, thÃ¬:

T=Z/sqrt(Î½T)

sáº½ tuÃ¢n theo **t-distribution** vá»›i Î½\nuÎ½ báº­c tá»± do (degrees of freedom,
df).

## **Äáº·c Ä‘iá»ƒm**

-   **Äá»‘i xá»©ng** quanh 0 (giá»‘ng phÃ¢n phá»‘i chuáº©n)

-   **ÄuÃ´i dÃ y hÆ¡n** phÃ¢n phá»‘i chuáº©n â†’ cho phÃ©p â€œnhiá»u biáº¿n Ä‘á»™ng hÆ¡nâ€
    khi cá»¡ máº«u nhá»

-   Khi sá»‘ báº­c tá»± do Î½â†’âˆ, phÃ¢n phá»‘i t tiáº¿n gáº§n Ä‘áº¿n chuáº©n chuáº©n hÃ³a
    N(0,1).

## **á»¨ng dá»¥ng**

1.  **Kiá»ƒm Ä‘á»‹nh giáº£ thuyáº¿t**:

```         
-    Kiá»ƒm Ä‘á»‹nh má»™t máº«u t-test.

-    Kiá»ƒm Ä‘á»‹nh hai máº«u Ä‘á»™c láº­p.

-    Kiá»ƒm Ä‘á»‹nh cáº·p máº«u (paired t-test).
```

2.  **Khoáº£ng tin cáº­y (Confidence Interval)** cho trung bÃ¬nh khi khÃ´ng
    biáº¿t phÆ°Æ¡ng sai.

### 3.2. PhÃ¢n tÃ­ch residuals

Trong há»“i quy, **residual** (sá»‘ dÆ°, hay pháº§n dÆ°) lÃ  **khoáº£ng cÃ¡ch dá»c**
giá»¯a giÃ¡ trá»‹ quan sÃ¡t thá»±c táº¿ vÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh.

```{r}
# Váº½ residuals
ggplot(sim1_extended, aes(x = x)) +
  geom_ref_line(h = 0) +
  geom_point(aes(y = resid_lm), color = "red", alpha = 0.7) +
  geom_point(aes(y = resid_loess), color = "blue", alpha = 0.7) +
  labs(title = "So sÃ¡nh Residuals: Linear Model (Ä‘á») vs LOESS (xanh)",
       x = "X", y = "Residuals")

```

### 3.3. Sá»­ dá»¥ng gather_predictions() vÃ  spread_predictions()

gather_predictions() DÃ¹ng khi cÃ³ nhiá»u mÃ´ hÃ¬nh vÃ  muá»‘n thu tháº­p (gather)
táº¥t cáº£ dá»± Ä‘oÃ¡n vÃ o má»™t cá»™t duy nháº¥t.

-   `.model` â†’ tÃªn mÃ´ hÃ¬nh.

<!-- -->

-   `.pred` â†’ giÃ¡ trá»‹ dá»± Ä‘oÃ¡n.

**`spread_predictions()`** NgÆ°á»£c láº¡i vá»›i gather. DÃ¹ng khi muá»‘n tráº£i
(spread) dá»± Ä‘oÃ¡n cá»§a nhiá»u mÃ´ hÃ¬nh thÃ nh **nhiá»u cá»™t riÃªng biá»‡t**.

.

```{r}
# Táº¡o grid cho dá»± Ä‘oÃ¡n
grid <- sim1 %>%
  data_grid(x)
```

```{r}
# Sá»­ dá»¥ng gather_predictions
grid_gather <- grid %>% gather_predictions(sim1_lm, sim1_loess)

print("Káº¿t quáº£ gather_predictions:")
head(grid_gather)
```

```{r}
# Sá»­ dá»¥ng spread_predictions
grid_spread <- grid %>% spread_predictions (sim1_lm, sim1_loess)

print("Káº¿t quáº£ spread_predictions:")
head(grid_spread)
```

```{r}
# Váº½ biá»ƒu Ä‘á»“ tá»« gather_predictions
ggplot(sim1, aes(x = x, y = y)) +
  geom_point() +
  geom_line(aes(y = pred, color = model), data = grid_gather, size = 1) +
  labs(title = "Multiple Models using gather_predictions()")
```

### CÃ¢u há»i vÃ  Ä‘Ã¡p Ã¡n - Pháº§n 3 (25 Ä‘iá»ƒm)

**CÃ¢u 1: (8 Ä‘iá»ƒm)** So sÃ¡nh Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a `lm()` vÃ  `loess()`. Khi
nÃ o nÃªn sá»­ dá»¥ng tá»«ng phÆ°Æ¡ng phÃ¡p?

**ÄÃ¡p Ã¡n:**

lm(): MÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh, nhanh, dá»… hiá»ƒu, phÃ¹ há»£p khi má»‘i quan
há»‡ giá»¯a biáº¿n phá»¥ thuá»™c vÃ  Ä‘á»™c láº­p lÃ  tuyáº¿n tÃ­nh.

loess(): MÃ´ hÃ¬nh há»“i quy phi tuyáº¿n tÃ­nh, linh hoáº¡t, xá»­ lÃ½ dá»¯ liá»‡u phi
tuyáº¿n tá»‘t nhÆ°ng cháº­m vá»›i dá»¯ liá»‡u lá»›n.

Khi nÃ o dÃ¹ng: DÃ¹ng lm() khi dá»¯ liá»‡u cÃ³ xu hÆ°á»›ng tuyáº¿n tÃ­nh; dÃ¹ng loess()
khi dá»¯ liá»‡u cÃ³ quan há»‡ phá»©c táº¡p, khÃ´ng tuyáº¿n tÃ­nh.

**CÃ¢u 2: (9 Ä‘iá»ƒm)** Giáº£i thÃ­ch sá»± khÃ¡c biá»‡t giá»¯a `add_predictions()`,
`gather_predictions()`, vÃ  `spread_predictions()`. Cho vÃ­ dá»¥ khi nÃ o sá»­
dá»¥ng tá»«ng hÃ m.

**ÄÃ¡p Ã¡n:**

add_predictions(): ThÃªm cá»™t dá»± Ä‘oÃ¡n vÃ o má»™t dataframe cÃ³ dá»¯ liá»‡u gá»‘c.

gather_predictions(): Gom dá»± Ä‘oÃ¡n tá»« nhiá»u mÃ´ hÃ¬nh khÃ¡c nhau thÃ nh dáº¡ng
â€œdÃ iâ€ Ä‘á»ƒ so sÃ¡nh.

spread_predictions(): Biáº¿n dá»¯ liá»‡u dá»± Ä‘oÃ¡n tá»« dáº¡ng â€œdÃ iâ€ thÃ nh â€œrá»™ngâ€ Ä‘á»ƒ
so sÃ¡nh mÃ´ hÃ¬nh.

VÃ­ dá»¥:

DÃ¹ng add_predictions() Ä‘á»ƒ thÃªm dá»± Ä‘oÃ¡n vÃ o dá»¯ liá»‡u gá»‘c.

DÃ¹ng gather_predictions() khi cÃ³ nhiá»u mÃ´ hÃ¬nh vÃ  muá»‘n so sÃ¡nh chung.

DÃ¹ng spread_predictions() khi muá»‘n xem dá»± Ä‘oÃ¡n tá»«ng mÃ´ hÃ¬nh bÃªn cáº¡nh
nhau.

**CÃ¢u 3: (8 Ä‘iá»ƒm)** Táº¡i sao viá»‡c váº½ `geom_ref_line(h = 0)` quan trá»ng
khi phÃ¢n tÃ­ch residuals? Residuals tá»‘t cáº§n cÃ³ nhá»¯ng tÃ­nh cháº¥t gÃ¬?

**ÄÃ¡p Ã¡n:**

Váº½ geom_ref_line(h = 0) giÃºp dá»… nháº­n biáº¿t cÃ¡c residuals lá»‡ch khá»i 0, thá»ƒ
hiá»‡n sai sá»‘ dá»± Ä‘oÃ¡n.

Residuals tá»‘t cáº§n: phÃ¢n bá»‘ ngáº«u nhiÃªn quanh 0, khÃ´ng cÃ³ xu hÆ°á»›ng, phÆ°Æ¡ng
sai Ä‘á»“ng nháº¥t, khÃ´ng cÃ³ outliers lá»›n.

## Pháº§n 4: LÃ m viá»‡c vá»›i dá»¯ liá»‡u categorical (30 Ä‘iá»ƒm)

### 4.1. PhÃ¢n tÃ­ch sim2 (má»™t biáº¿n categorical)

```{r}
# Xem dá»¯ liá»‡u sim2
print("Dá»¯ liá»‡u sim2:")
head(sim2)
```

```{r}
# MÃ´ hÃ¬nh cÃ³ intercept
mod2_with_intercept <- lm(y ~ x, data = sim2)

mod2_with_intercept
```

y \~ x â†’ mÃ´ hÃ¬nh cÃ³ intercept (Î²0 + Î²1x).

```{r}
# MÃ´ hÃ¬nh khÃ´ng cÃ³ intercept
mod2_without_intercept <-  lm(y ~ x - 1, data = sim2)

mod2_without_intercept
```

y \~ x - 1 â†’ mÃ´ hÃ¬nh khÃ´ng cÃ³ intercept (chá»‰ Î²1x).

##### KhÃ¡c biá»‡t:

-   CÃ³ intercept: Ä‘Æ°á»ng há»“i quy cÃ³ thá»ƒ dá»‹ch chuyá»ƒn lÃªn/xuá»‘ng trá»¥c tung.

-   KhÃ´ng intercept: Ä‘Æ°á»ng há»“i quy báº¯t buá»™c Ä‘i qua gá»‘c (0,0).

```{r}
# So sÃ¡nh predictions
grid2 <-sim2 %>% data_grid(x) %>% spread_predictions (mod2_with_intercept, mod2_without_intercept)

print("So sÃ¡nh predictions:")
grid2
```

-   data_grid(x) â†’ táº¡o lÆ°á»›i giÃ¡ trá»‹ x Ä‘á»ƒ tÃ­nh prediction.

-   spread_predictions() â†’ tÃ­nh giÃ¡ trá»‹ dá»± Ä‘oÃ¡n tá»« cáº£ 2 mÃ´ hÃ¬nh trÃªn
    cÃ¹ng táº­p grid.

    -   mod2_with_intercept: dá»± Ä‘oÃ¡n dá»‹ch chuyá»ƒn theo intercept.

    -   mod2_without_intercept: dá»± Ä‘oÃ¡n Ä‘i qua gá»‘c (0,0).

Trong thá»±c táº¿ khi bá» intercept khi báº¡n cháº¯c cháº¯n dá»¯ liá»‡u cÃ³ quan há»‡
tuyáº¿n tÃ­nh Ä‘i qua gá»‘c (vÃ­ dá»¥: chiá»u cao = 0 â†’ cÃ¢n náº·ng = 0).

### 4.2. PhÃ¢n tÃ­ch model matrix

```{r}
# Xem model matrix cá»§a sim3 (continuous * categorical)
x3 <- model_matrix(y ~ x1 * x2, data = sim3)
print("Model matrix cá»§a x1 * x2 (sim3):")
head(x3)
```

```{r}
# Xem model matrix cá»§a sim4 (continuous * continuous)
x4 <- model_matrix(y ~ x1 * x2, data = sim4)
print("Model matrix cá»§a x1 * x2 (sim4):")
head(x4)
```

-   Model matrix: trá»±c quan dá»¯ liá»‡u Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh features trÆ°á»›c
    khi training. Trong ML gá»i lÃ  feature engineering / encoding.

-   thÃªm feature phi tuyáº¿n (non-linear feature) Ä‘á»ƒ mÃ´ hÃ¬nh tuyáº¿n tÃ­nh
    trá»Ÿ nÃªn máº¡nh hÆ¡n.

### 4.3. So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh trÃªn sim4

```{r}
# XÃ¢y dá»±ng hai mÃ´ hÃ¬nh
mod1_sim4 <- lm(y ~ x1 + x2, data = sim4)
mod2_sim4 <- lm(y ~ x1 * x2, data = sim4)
```

```{r}
mod1_sim4
mod2_sim4
```

```{r}
# ThÃªm residuals
sim4_mods <- gather_residuals(sim4, mod1_sim4, mod2_sim4)
```

```{r}
# Váº½ frequency plot cá»§a residuals
ggplot(sim4_mods, aes(x = resid, colour = model)) +
  geom_freqpoly(binwidth = 0.5) +
  geom_rug() +
  labs(title = "PhÃ¢n phá»‘i Residuals cá»§a hai mÃ´ hÃ¬nh")
```

```{r}
# Váº½ frequency plot cá»§a absolute residuals
ggplot(sim4_mods, aes(x = abs(resid), colour = model)) +
  geom_freqpoly(binwidth = 0.5) +
  geom_rug() +
  labs(title = "PhÃ¢n phá»‘i |Residuals| cá»§a hai mÃ´ hÃ¬nh")
```

```{r}
# So sÃ¡nh standard deviation cá»§a residuals
sim4_comparison <- sim4_mods %>%
  group_by(model) %>%
  summarise(
    mean_resid = mean(resid),
    sd_resid = sd(resid),
    mad_resid = mad(resid),
    .groups = 'drop')

print("So sÃ¡nh cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh:")
sim4_comparison
```

### CÃ¢u há»i vÃ  Ä‘Ã¡p Ã¡n - Pháº§n 4 (30 Ä‘iá»ƒm)

**CÃ¢u 1: (10 Ä‘iá»ƒm)** Giáº£i thÃ­ch sá»± khÃ¡c biá»‡t giá»¯a mÃ´ hÃ¬nh `y ~ x - 1` vÃ 
`y ~ x` khi x lÃ  categorical variable. Predictions cÃ³ giá»‘ng nhau khÃ´ng
vÃ  táº¡i sao?

**ÄÃ¡p Ã¡n:**

MÃ´ hÃ¬nh y \~ x - 1 khÃ´ng cÃ³ intercept, má»—i má»©c cá»§a biáº¿n phÃ¢n loáº¡i x cÃ³
há»‡ sá»‘ riÃªng thá»ƒ hiá»‡n giÃ¡ trá»‹ trung bÃ¬nh tá»«ng nhÃ³m.

MÃ´ hÃ¬nh y \~ x cÃ³ intercept, cÃ¡c há»‡ sá»‘ cá»§a má»©c x Ä‘Æ°á»£c tÃ­nh so vá»›i má»©c
tham chiáº¿u.

Dá»± Ä‘oÃ¡n khÃ¡c nhau: vá»›i y \~ x - 1, dá»± Ä‘oÃ¡n lÃ  giÃ¡ trá»‹ trung bÃ¬nh nhÃ³m;
vá»›i y \~ x, dá»± Ä‘oÃ¡n lÃ  intercept cá»™ng há»‡ sá»‘ cá»§a nhÃ³m, vá» cÆ¡ báº£n tÆ°Æ¡ng
Ä‘Æ°Æ¡ng nhÆ°ng biá»ƒu diá»…n khÃ¡c.

**CÃ¢u 2: (10 Ä‘iá»ƒm)** Trong model matrix cá»§a `x1 * x2` (sim3), giáº£i thÃ­ch
Ã½ nghÄ©a cá»§a cÃ¡c cá»™t `x1:x2b`, `x1:x2c`, `x1:x2d`. Táº¡i sao interaction
term quan trá»ng?

**ÄÃ¡p Ã¡n:**

Trong model matrix cá»§a x1 \* x2, cÃ¡c cá»™t x1:x2b, x1:x2c, x1:x2d lÃ  cÃ¡c
tÆ°Æ¡ng tÃ¡c giá»¯a biáº¿n x1 vÃ  tá»«ng má»©c cá»§a biáº¿n phÃ¢n loáº¡i x2 (ngoáº¡i trá»« má»©c
tham chiáº¿u).

Ã nghÄ©a: thá»ƒ hiá»‡n áº£nh hÆ°á»Ÿng cá»§a x1 phá»¥ thuá»™c vÃ o tá»«ng nhÃ³m cá»§a x2.

TÆ°Æ¡ng tÃ¡c quan trá»ng vÃ¬ nÃ³ cho phÃ©p mÃ´ hÃ¬nh náº¯m báº¯t hiá»‡u á»©ng káº¿t há»£p
khÃ´ng Ä‘Æ¡n giáº£n chá»‰ lÃ  tá»•ng cÃ¡c biáº¿n mÃ  thay Ä‘á»•i theo nhÃ³m.

**CÃ¢u 3: (10 Ä‘iá»ƒm)** Dá»±a vÃ o káº¿t quáº£ phÃ¢n tÃ­ch sim4, mÃ´ hÃ¬nh nÃ o tá»‘t hÆ¡n
giá»¯a `y ~ x1 + x2` vÃ  `y ~ x1 * x2`? Sá»­ dá»¥ng nhá»¯ng tiÃªu chÃ­ nÃ o Ä‘á»ƒ Ä‘Ã¡nh
giÃ¡?

**ÄÃ¡p Ã¡n:**

So sÃ¡nh hai mÃ´ hÃ¬nh y \~ x1 + x2 vÃ  y \~ x1 \* x2 dá»±a trÃªn:

1.  GiÃ¡ trá»‹ AIC hoáº·c BIC, mÃ´ hÃ¬nh nÃ o nhá» hÆ¡n thÃ¬ tá»‘t hÆ¡n.

2.  Adjusted R-squared, giÃ¡ trá»‹ cao hÆ¡n nghÄ©a lÃ  mÃ´ hÃ¬nh giáº£i thÃ­ch biáº¿n
    Ä‘á»™ng tá»‘t hÆ¡n.

3.  Kiá»ƒm Ä‘á»‹nh ANOVA xem tÆ°Æ¡ng tÃ¡c cÃ³ Ã½ nghÄ©a thá»‘ng kÃª khÃ´ng.

MÃ´ hÃ¬nh cÃ³ tÆ°Æ¡ng tÃ¡c (y \~ x1 \* x2) tá»‘t hÆ¡n náº¿u tÆ°Æ¡ng tÃ¡c giÃºp cáº£i
thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ phÃ¹ há»£p cá»§a mÃ´ hÃ¬nh.

## BÃ i táº­p thá»±c hÃ nh

### BÃ i táº­p 1: Táº¡o vÃ  phÃ¢n tÃ­ch mÃ´ hÃ¬nh cá»§a riÃªng báº¡n (10 Ä‘iá»ƒm)

```{r}
# 1. Táº¡o dá»¯ liá»‡u mÃ´ phá»ng vá»›i noise khÃ¡c nhau
set.seed(123)
my_data <- tibble(
  x = seq(1, 20, by = 0.5),
  y_linear = 2 * x + 5 + rnorm(length(x), sd = 2),
  y_nonlinear = 2 * x + 0.1 * x^2 - 10 + rnorm(length(x), sd = 3)
)
```

# 2. XÃ¢y dá»±ng mÃ´ hÃ¬nh linear cho cáº£ hai biáº¿n y

```{r}
# 2. XÃ¢y dá»±ng mÃ´ hÃ¬nh linear cho cáº£ hai biáº¿n y
model_linear <- lm(y_linear ~ x, data = my_data)
model_nonlinear <- lm(y_nonlinear ~ x, data = my_data)

# 3. Tá»•ng quan káº¿t quáº£ mÃ´ hÃ¬nh
summary(model_linear)
summary(model_nonlinear)

# 4. Váº½ dá»¯ liá»‡u vÃ  Ä‘Æ°á»ng há»“i quy

# Biá»ƒu Ä‘á»“ cho y_linear
p1 <- ggplot(my_data, aes(x = x, y = y_linear)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  ggtitle("Linear model: y_linear ~ x")

# Biá»ƒu Ä‘á»“ cho y_nonlinear
p2 <- ggplot(my_data, aes(x = x, y = y_nonlinear)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  ggtitle("Linear model: y_nonlinear ~ x")

print(p1)
print(p2)

# 5. Nháº­n xÃ©t ngáº¯n
cat("MÃ´ hÃ¬nh linear vá»›i y_linear cho káº¿t quáº£ tá»‘t hÆ¡n do y_linear gáº§n vá»›i dáº¡ng tuyáº¿n tÃ­nh.\n")
cat("MÃ´ hÃ¬nh linear vá»›i y_nonlinear khÃ´ng phÃ¹ há»£p tá»‘t do y_nonlinear cÃ³ thÃ nh pháº§n phi tuyáº¿n.\n")

```

### Pháº§n 1: Trá»±c quan hÃ³a dá»¯ liá»‡u (2 Ä‘iá»ƒm)

-   Váº½ scatter plot cho cáº£ y_linear vÃ  y_nonlinear theo x

-   Sá»­ dá»¥ng facet_wrap() hoáº·c facet_grid() Ä‘á»ƒ hiá»ƒn thá»‹ 2 biá»ƒu Ä‘á»“ cáº¡nh
    nhau

-   Äáº·t tiÃªu Ä‘á» vÃ  nhÃ£n trá»¥c rÃµ rÃ ng

```{r}
my_data_long <- my_data %>%
  pivot_longer(cols = starts_with("y"), names_to = "type", values_to = "y")

ggplot(my_data_long, aes(x = x, y = y)) +
  geom_point(color = "gray20") +
  facet_wrap(~type, scales = "free_y") +
  labs(
    title = "Biá»ƒu Ä‘á»“ scatter cá»§a y_linear vÃ  y_nonlinear",
    x = "x",
    y = "GiÃ¡ trá»‹ y"
  ) +
  theme_minimal()

```

### **Pháº§n 2: XÃ¢y dá»±ng mÃ´ hÃ¬nh Linear (2 Ä‘iá»ƒm)**

-   XÃ¢y dá»±ng mÃ´ hÃ¬nh lm() cho y_linear \~ x

-   XÃ¢y dá»±ng mÃ´ hÃ¬nh lm() cho y_nonlinear \~ x

-   In ra summary cá»§a cáº£ 2 mÃ´ hÃ¬nh

-   Nháº­n xÃ©t vá» R-squared vÃ  cÃ¡c há»‡ sá»‘ há»“i quy

```{r}
model_linear <- lm(y_linear ~ x, data = my_data)
model_nonlinear <- lm(y_nonlinear ~ x, data = my_data)

summary(model_linear)
summary(model_nonlinear)

```

**Nháº­n xÃ©t:**

-   model_linear cÃ³ R-squared ráº¥t cao (\~0.98), cho tháº¥y mÃ´ hÃ¬nh tuyáº¿n
    tÃ­nh fit ráº¥t tá»‘t dá»¯ liá»‡u tuyáº¿n tÃ­nh.

-   model_nonlinear cÃ³ R-squared tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ (khoáº£ng 0.9 hoáº·c nhá»
    hÆ¡n), vÃ¬ dá»¯ liá»‡u tháº­t cÃ³ quan há»‡ phi tuyáº¿n (cÃ³ thÃ nh pháº§n xÂ²).

### **Pháº§n 3: ThÃªm predictions vÃ  residuals (2 Ä‘iá»ƒm)**

-   Sá»­ dá»¥ng add_predictions() Ä‘á»ƒ thÃªm giÃ¡ trá»‹ dá»± Ä‘oÃ¡n

-   Sá»­ dá»¥ng add_residuals() Ä‘á»ƒ thÃªm residuals

-   Táº¡o dataframe chá»©a cáº£ predictions vÃ  residuals cá»§a cáº£ 2 mÃ´ hÃ¬nh

```{r}
my_data_extended <- my_data %>%
  add_predictions(model_linear, var = "pred_linear") %>%
  add_residuals(model_linear, var = "resid_linear") %>%
  add_predictions(model_nonlinear, var = "pred_nonlinear") %>%
  add_residuals(model_nonlinear, var = "resid_nonlinear")

head(my_data_extended)

```

### **Pháº§n 4: Váº½ biá»ƒu Ä‘á»“ vá»›i Ä‘Æ°á»ng há»“i quy (2 Ä‘iá»ƒm)**

-   Váº½ scatter plot vá»›i Ä‘iá»ƒm dá»¯ liá»‡u gá»‘c

-   ThÃªm Ä‘Æ°á»ng há»“i quy tá»« mÃ´ hÃ¬nh (sá»­ dá»¥ng geom_line() vá»›i predictions)

-   Táº¡o 2 biá»ƒu Ä‘á»“ riÃªng biá»‡t cho y_linear vÃ  y_nonlinear

-   So sÃ¡nh Ä‘á»™ fit cá»§a mÃ´ hÃ¬nh vá»›i dá»¯ liá»‡u

-   Äá»‹nh dáº¡ng:

-   MÃ u Ä‘á» cho Ä‘Æ°á»ng há»“i quy

-   Äiá»ƒm dá»¯ liá»‡u mÃ u Ä‘en hoáº·c xÃ¡m

-   Sá»­ dá»¥ng facet_wrap() Ä‘á»ƒ tÃ¡ch biá»‡t 2 trÆ°á»ng há»£p

```{r}
my_data_long_pred <- my_data_extended %>%
  pivot_longer(
    cols = c(y_linear, y_nonlinear, pred_linear, pred_nonlinear),
    names_to = c(".value", "type"),
    names_pattern = "(y|pred)_(.*)"
  )

ggplot(my_data_long_pred, aes(x = x)) +
  geom_point(aes(y = y), color = "black") +
  geom_line(aes(y = pred, color = "Há»“i quy (Linear model)"), size = 1) +
  facet_wrap(~type, scales = "free_y") +
  scale_color_manual(values = c("Há»“i quy (Linear model)" = "red")) +
  labs(
    title = "Biá»ƒu Ä‘á»“ dá»¯ liá»‡u vÃ  Ä‘Æ°á»ng há»“i quy",
    x = "x",
    y = "GiÃ¡ trá»‹ y"
  ) +
  theme_minimal()

```

**Nháº­n xÃ©t:**

-   Vá»›i y_linear, Ä‘Æ°á»ng há»“i quy khá»›p ráº¥t sÃ¡t dá»¯ liá»‡u.

-   Vá»›i y_nonlinear, Ä‘Æ°á»ng há»“i quy khÃ´ng mÃ´ táº£ Ä‘Æ°á»£c Ä‘á»™ cong cá»§a dá»¯ liá»‡u.

### **Pháº§n 5: PhÃ¢n tÃ­ch Residuals (1 Ä‘iá»ƒm)**

-   Váº½ residual plot (x vs residuals) cho cáº£ 2 mÃ´ hÃ¬nh

-   ThÃªm Ä‘Æ°á»ng tham chiáº¿u geom_hline(yintercept = 0) mÃ u Ä‘á»

-   Nháº­n xÃ©t vá» pattern cá»§a residuals

```{r}
resid_long <- my_data_extended %>%
  select(x, resid_linear, resid_nonlinear) %>%
  pivot_longer(cols = starts_with("resid"), names_to = "model", values_to = "resid")

ggplot(resid_long, aes(x = x, y = resid)) +
  geom_point(color = "gray20") +
  geom_hline(yintercept = 0, color = "red") +
  facet_wrap(~model, scales = "free_y") +
  labs(
    title = "Residual plots cho hai mÃ´ hÃ¬nh",
    x = "x",
    y = "Residuals"
  ) +
  theme_minimal()

```

### **CÃ¢u há»i:**

1.  MÃ´ hÃ¬nh nÃ o cÃ³ residuals phÃ¢n bá»‘ tá»‘t hÆ¡n?

```         
MÃ´ hÃ¬nh y_linear cÃ³ residuals phÃ¢n bá»‘ ngáº«u nhiÃªn quanh 0, tá»‘t hÆ¡n.
```

2.  CÃ³ tháº¥y pattern nÃ o trong residuals cá»§a model_nonlinear khÃ´ng?

```         
CÃ³ dáº¡ng cong (u-shape).
```

3.  Pattern Ä‘Ã³ cho biáº¿t Ä‘iá»u gÃ¬ vá» mÃ´ hÃ¬nh?

```         
MÃ´ hÃ¬nh tuyáº¿n tÃ­nh khÃ´ng báº¯t Ä‘Æ°á»£c má»‘i quan há»‡ phi tuyáº¿n, nÃªn residuals thá»ƒ hiá»‡n xu hÆ°á»›ng cÃ³ há»‡ thá»‘ng.
```

### **Pháº§n 6: So sÃ¡nh cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh (1 Ä‘iá»ƒm)**

1.  TÃ­nh cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡:

-   Mean Absolute Error (MAE): mean(abs(resid))

-   Root Mean Squared Error (RMSE): sqrt(mean(resid\^2))

-   Standard deviation cá»§a residuals

```{r}
mae_linear <- mean(abs(resid(model_linear)))
mae_nonlinear <- mean(abs(resid(model_nonlinear)))

rmse_linear <- sqrt(mean(resid(model_linear)^2))
rmse_nonlinear <- sqrt(mean(resid(model_nonlinear)^2))

sd_linear <- sd(resid(model_linear))
sd_nonlinear <- sd(resid(model_nonlinear))
```

**Nháº­n xÃ©t:**

-   MÃ´ hÃ¬nh `y_linear` cÃ³ MAE vÃ  RMSE tháº¥p hÆ¡n rÃµ rá»‡t â†’ dá»± Ä‘oÃ¡n chÃ­nh
    xÃ¡c hÆ¡n.

-   `y_nonlinear` cÃ³ sai sá»‘ cao hÆ¡n do chÆ°a mÃ´ táº£ Ä‘Ãºng dáº¡ng dá»¯ liá»‡u.

2.  Táº¡o báº£ng so sÃ¡nh 2 mÃ´ hÃ¬nh

```{r}
comparison <- tibble(
  Model = c("y_linear", "y_nonlinear"),
  MAE = c(mae_linear, mae_nonlinear),
  RMSE = c(rmse_linear, rmse_nonlinear),
  SD_Resid = c(sd_linear, sd_nonlinear)
)

comparison
```

### **Pháº§n 7: Cáº£i thiá»‡n mÃ´ hÃ¬nh phi tuyáº¿n (Bonus)**

-   XÃ¢y dá»±ng mÃ´ hÃ¬nh polynomial cho y_nonlinear: lm(y_nonlinear \~ x +
    I(x\^2))

-   So sÃ¡nh vá»›i mÃ´ hÃ¬nh linear Ä‘Æ¡n giáº£n

-   Váº½ cáº£ 3 Ä‘Æ°á»ng: dá»¯ liá»‡u gá»‘c, linear model, polynomial model

-   Nháº­n xÃ©t vá» sá»± cáº£i thiá»‡n

```{r}
model_poly <- lm(y_nonlinear ~ x + I(x^2), data = my_data)
summary(model_poly)

my_data_poly <- my_data %>%
  add_predictions(model_poly, var = "pred_poly")

ggplot(my_data_poly, aes(x = x)) +
  geom_point(aes(y = y_nonlinear), color = "black") +
  geom_line(aes(y = pred_poly, color = "Polynomial (x + xÂ²)"), size = 1.2) +
  geom_line(aes(y = pred_nonlinear, color = "Linear model"), data = my_data_extended) +
  scale_color_manual(values = c("Polynomial (x + xÂ²)" = "blue", "Linear model" = "red")) +
  labs(
    title = "So sÃ¡nh mÃ´ hÃ¬nh Linear vÃ  Polynomial cho y_nonlinear",
    x = "x",
    y = "GiÃ¡ trá»‹ y"
  ) +
  theme_minimal()

```

### **CÃ¢u há»i**

1.  Táº¡i sao mÃ´ hÃ¬nh linear khÃ´ng fit tá»‘t vá»›i y_nonlinear?

```         
VÃ¬ quan há»‡ giá»¯a y_nonlinear vÃ  x lÃ  phi tuyáº¿n (cÃ³ thÃ nh pháº§n báº­c 2), mÃ´ hÃ¬nh tuyáº¿n tÃ­nh khÃ´ng mÃ´ táº£ Ä‘Æ°á»£c Ä‘á»™ cong Ä‘Ã³.
```

2.  LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¡t hiá»‡n má»™t mÃ´ hÃ¬nh khÃ´ng phÃ¹ há»£p thÃ´ng qua
    residual plot?

```         
Khi residuals khÃ´ng phÃ¢n bá»‘ ngáº«u nhiÃªn quanh 0 mÃ  cÃ³ pattern (vÃ­ dá»¥: cong, tÄƒng dáº§n, giáº£m dáº§n theo x). 
```

3.  Khi nÃ o nÃªn sá»­ dá»¥ng polynomial regression thay vÃ¬ linear regression?

```         
Khi má»‘i quan há»‡ giá»¯a biáº¿n Ä‘á»™c láº­p vÃ  phá»¥ thuá»™c cÃ³ dáº¡ng cong (nonlinear), khÃ´ng thá»ƒ mÃ´ táº£ tá»‘t báº±ng Ä‘Æ°á»ng tháº³ng.
```

## Káº¿t luáº­n

Trong bÃ i lab nÃ y, chÃºng ta Ä‘Ã£ há»c Ä‘Æ°á»£c:

-   CÃ¡ch xÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh tuyáº¿n tÃ­nh
-   áº¢nh hÆ°á»Ÿng cá»§a outliers Ä‘áº¿n mÃ´ hÃ¬nh
-   CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘o khoáº£ng cÃ¡ch khÃ¡c nhau
-   CÃ¡ch trá»±c quan hÃ³a mÃ´ hÃ¬nh vÃ  residuals
-   Sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ há»— trá»£ trong package `modelr`
-   LÃ m viá»‡c vá»›i dá»¯ liá»‡u categorical vÃ  interaction terms

Nhá»¯ng ká»¹ nÄƒng nÃ y lÃ  ná»n táº£ng quan trá»ng cho viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u vÃ 
machine learning trong R.
